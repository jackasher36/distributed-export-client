# Kafka 大消息问题解决方案

## 问题描述

错误信息：
```
org.apache.kafka.common.errors.RecordTooLargeException: The message is 4480999 bytes when serialized which is larger than 1048576, which is the value of the max.request.size configuration.
```

**问题原因：**
- 附件任务消息序列化后约为 4.4MB
- Kafka 默认的 `max.request.size` 限制为 1MB
- 消息超过了默认大小限制

## 解决方案

我们提供了**两种解决方案**来处理大消息问题：

### 方案一：增加 Kafka 消息大小限制 ✅

#### 1. 服务器端配置 (docker-compose-kafka.yml)
```yaml
environment:
  # 支持大消息配置
  KAFKA_MESSAGE_MAX_BYTES: 10485760        # 10MB
  KAFKA_REPLICA_FETCH_MAX_BYTES: 10485760  # 10MB  
  KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600 # 100MB
```

#### 2. 生产者配置 (KafkaConfig.java)
```java
// 消息大小配置 - 支持大消息
configProps.put(ProducerConfig.MAX_REQUEST_SIZE_CONFIG, 10 * 1024 * 1024); // 10MB
configProps.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 64 * 1024 * 1024); // 64MB缓冲区
```

#### 3. 消费者配置 (KafkaConfig.java)
```java
// 消费者大消息配置
props.put(ConsumerConfig.MAX_PARTITION_FETCH_BYTES_CONFIG, 10 * 1024 * 1024); // 10MB
props.put(ConsumerConfig.FETCH_MAX_BYTES_CONFIG, 50 * 1024 * 1024); // 50MB
```

#### 4. 应用配置 (application-demo.yml)
```yaml
spring:
  kafka:
    consumer:
      max-partition-fetch-bytes: 10485760  # 10MB
      fetch-max-bytes: 52428800  # 50MB
    producer:
      buffer-memory: 67108864  # 64MB
      max-request-size: 10485760  # 10MB
```

### 方案二：消息分片处理 ✅

#### 1. 消息分片器 (MessageSplitter.java)
- 自动检测大消息
- 将大消息分片为多个小消息
- 每个分片最多包含 1000 条记录
- 智能大小估算

#### 2. 智能发送策略 (KafkaProducerService.java)
```java
// 检查消息是否需要分片（5MB 限制）
if (MessageSplitter.needsSplit(message, 5 * 1024 * 1024)) {
    log.info("消息过大，进行分片处理，SubTaskID: {}", message.getSubTaskId());
    sendMessageWithSplit(message);
} else {
    log.debug("消息大小适中，直接发送，SubTaskID: {}", message.getSubTaskId());
    sendSingleMessage(message);
}
```

## 使用步骤

### 1. 重启 Kafka 环境
```bash
# 使用新的配置重启 Kafka
./restart-kafka-with-config.sh
```

### 2. 重启应用程序
```bash
# 重启应用以应用新的配置
mvn spring-boot:run
```

### 3. 验证修复效果
- 触发附件处理任务
- 查看日志确认消息发送成功
- 使用 Kafka UI 监控消息

## 配置详情

### 消息大小限制对比

| 配置项 | 默认值 | 新配置值 | 说明 |
|--------|--------|----------|------|
| max.request.size | 1MB | 10MB | 生产者最大请求大小 |
| message.max.bytes | 1MB | 10MB | 主题最大消息大小 |
| max.partition.fetch.bytes | 1MB | 10MB | 消费者单次获取大小 |
| fetch.max.bytes | 50MB | 50MB | 消费者总获取大小 |
| buffer.memory | 32MB | 64MB | 生产者缓冲区 |

### 分片策略

| 参数 | 值 | 说明 |
|------|----|----|
| 分片触发阈值 | 5MB | 超过此大小自动分片 |
| 每个分片最大记录数 | 1000条 | 确保分片大小合理 |
| 分片命名规则 | `{subTaskId}_chunk_{序号}` | 便于追踪和调试 |

## 监控和调试

### 1. 查看分片日志
```bash
grep "分片" logs/application.log
```

### 2. Kafka UI 监控
访问 http://localhost:8080 查看：
- 消息大小分布
- 分区分布情况
- 消费滞后情况

### 3. 主题配置验证
```bash
docker exec kafka kafka-topics --describe --topic attachment-processing-topic --bootstrap-server localhost:9092
```

## 性能影响

### 优势
- ✅ 支持大消息处理
- ✅ 自动分片，透明处理
- ✅ 保持消息顺序（同一分区）
- ✅ 降级机制（失败时转异步）

### 注意事项
- 📊 消息分片会增加延迟
- 💾 需要更多内存和存储
- 🔧 需要合理配置分区数量
- 📈 监控消费者处理能力

## 故障处理

### 1. 如果还是失败
```bash
# 检查 Kafka 配置是否生效
docker exec kafka kafka-configs --describe --entity-type topics --entity-name attachment-processing-topic --bootstrap-server localhost:9092

# 查看 Kafka 日志
docker-compose -f docker-compose-kafka.yml logs kafka
```

### 2. 降级策略
如果 Kafka 发送失败，系统会自动降级为 ASYNC 模式：
```java
private static void handleKafkaFailure(ProcessContext ctx, Exception e) {
    log.warn("【Kafka模式】发送失败，尝试降级为异步模式处理，SubTaskID: {}", ctx.subTaskId);
    try {
        processAsyncMode(ctx);
    } catch (Exception fallbackException) {
        log.error("【Kafka模式】降级处理也失败了，SubTaskID: {}", ctx.subTaskId, fallbackException);
    }
}
```

## 测试验证

### 1. 测试大消息
```bash
# 创建包含大量数据的导出任务
# 观察日志中的分片信息
tail -f logs/application.log | grep -E "(分片|chunk|Kafka)"
```

### 2. 监控消息
```bash
# 监听附件处理主题
docker exec -it kafka kafka-console-consumer --topic attachment-processing-topic --from-beginning --bootstrap-server localhost:9092
```

## 总结

通过以上两种方案的结合使用：

1. **方案一** 解决了 Kafka 配置限制问题
2. **方案二** 提供了智能分片处理能力
3. **降级机制** 确保系统可靠性

现在系统可以处理任意大小的附件任务消息，同时保持良好的性能和可靠性。
